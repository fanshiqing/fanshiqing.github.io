<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Shiqing Fan&#39;s Blog</title>
  
  <subtitle>Hello, world!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://fanshiqing.github.io/"/>
  <updated>2017-11-21T09:14:56.000Z</updated>
  <id>http://fanshiqing.github.io/</id>
  
  <author>
    <name>Shiqing Fan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>L05-Fault-tolerant consensus</title>
    <link href="http://fanshiqing.github.io/2017/10/26/L05-Fault-tolerant-consensus/"/>
    <id>http://fanshiqing.github.io/2017/10/26/L05-Fault-tolerant-consensus/</id>
    <published>2017-10-26T08:31:03.000Z</published>
    <updated>2017-11-21T09:14:56.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h2><ul><li>The consensus problem</li><li>Consensus with Byzantine Failures</li></ul><a id="more"></a><h2 id="Processor-Failures-in-Message-Passing"><a href="#Processor-Failures-in-Message-Passing" class="headerlink" title="Processor Failures in Message Passing"></a>Processor Failures in Message Passing</h2><ul><li><code>Fail stop</code>: at some point the processor stops taking steps<ul><li>at the processor’s final step, it might succeed in sending only <strong>a subset of the messages</strong> it is supposed to send, e.g.: <ul><li><code>Crash</code></li><li>Power outage</li><li>Hardware failure</li><li>Out of memory/disk full</li></ul></li><li>Strategies:<ul><li>Checkpoint state and restart (<strong>High latency</strong>)</li><li>Replicate state and fail over (失效备援) (<strong>High cost</strong>)</li></ul></li></ul></li><li><code>Byzantine</code>: <strong>Everything that is not fail stop</strong>. Processor changes state arbitrarily and sends message with arbitrary content. <ul><li>E.g.:<ul><li>Bit flip in memory or on disk corrupts data</li><li>Older version of code on one node sends (now) invalid messages</li><li>Node starts running malicious version of software</li></ul></li><li>Goal: turn into fail stop<ul><li>Checksums/ECC (Error Correction Code)</li><li>Assertions</li><li>Timeouts</li></ul></li></ul></li></ul><h3 id="Failure-Matrix"><a href="#Failure-Matrix" class="headerlink" title="Failure Matrix"></a>Failure Matrix</h3><p><img src="http://static.zybuluo.com/sqfan/a3w5713ss4n0p18hy8q194g4/image_1bvc1f0gs1721tm5m0h17fq170j9.png" alt="image_1bvc1f0gs1721tm5m0h17fq170j9.png-44.5kB"></p><h3 id="Negative-result-for-link-failures"><a href="#Negative-result-for-link-failures" class="headerlink" title="Negative result for link failures"></a>Negative result for <strong>link failures</strong></h3><p>It is impossible to reach consensus in case of link failures, even in the synchronous case, and even if one only wants to tolerate a single link failure.</p><p>Consensus under link failures: <code>the 2 generals problem</code>.</p><ul><li>There are two generals of the same army who have encamped a short distance apart.</li><li>Their objective is to capture a hill, which is possible only if they attack simultaneously. </li><li>If only one general attacks, he will be defeated. </li><li>The two generals can only communicate by sending messengers, <strong>which is not reliable</strong>. </li><li>Is it possible for them to attack simultaneously?</li></ul><p><img src="http://static.zybuluo.com/sqfan/y946xgli1f5gy525hehs9fft/image_1bves2gnp6fhd301i32eni1dos83.png" alt="image_1bves2gnp6fhd301i32eni1dos83.png-39.6kB"></p><p>See <a href="https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf" target="_blank" rel="external">Fischer/Lynch/Paterson</a> for more discussion.</p><h2 id="The-Consensus-Problem"><a href="#The-Consensus-Problem" class="headerlink" title="The Consensus Problem"></a>The Consensus Problem</h2><p>Each process starts with an individual <code>input</code> from a particular value set V. Processes may fail by crashing. All non-faulty processes are required to produce outputs from the value set V, subject to simple agreement and validity. A solution to the <strong>consensus proble</strong>m must guarantee the following:</p><ul><li><code>Termination</code>: Eventually every <strong>nonfaulty processor</strong> must decide on a value (decision is irrevocable).</li><li><code>Agreement</code>: All decisions by nonfaulty processors must be the same.</li><li><code>Validity</code>: If all inputs are the same, then the decision of a nonfaulty processor must equal the common input</li></ul><p>Once a processor crashes, it is of no interest to the algorithm, and no requirements are placed on its decision.</p><p><strong>f-resilient system</strong>:</p><ul><li>at most <code>f</code> processors may fail</li><li>The set of faulty processors may be <strong>different</strong> in different executions.</li></ul><p>In the last round:</p><ul><li><code>Clean crash</code>: none or all of the outgoing messages are sent</li><li><code>Not-clean crash</code>: an arbitrary set of its outgoing messages are delivered.</li></ul><h3 id="Consensus-algorithm-in-the-presence-of-crash-failures"><a href="#Consensus-algorithm-in-the-presence-of-crash-failures" class="headerlink" title="Consensus algorithm in the presence of crash failures"></a>Consensus algorithm in the presence of crash failures</h3><p>Each process maintains a set of the values it knows to exist in the system; initially, this set contains only its own input. At the first round, each process broadcasts its own input to all processes. For the subsequent f rounds, each process takes the following actions:</p><ul><li>updates its set by joining it with the sets received from other<br>processes, and</li><li>broadcasts any new additions to the set to all processes.</li></ul><p>After f+1 rounds, the process decides on the smallest value in its set.</p><p><img src="http://static.zybuluo.com/sqfan/lgf5n4i2dja5bmzism90iizr/image_1bveikf7ge2e1bc612bv1vie1e51g.png" alt="image_1bveikf7ge2e1bc612bv1vie1e51g.png-69.6kB"></p><p><img src="http://static.zybuluo.com/sqfan/xn1sspjaamzg1dl37xu5z5mm/image_1bvelori51oup18o6ddh1978mjk1t.png" alt="image_1bvelori51oup18o6ddh1978mjk1t.png-65.1kB"></p><ul><li>Intuition for <code>Agreement</code>: Assume that a process pi decides on a value x smaller than that decided by some other process p_j. Then, x has remained “hidden” from pj for (f+1) rounds. We have at most f faulty processes. A contradiction!!!</li><li>Number of processes: n &gt; f</li><li>Round Complexity: f + 1</li><li><strong>Message Complexity</strong>: (at most) n^2 * |V| messages, where V is the set of input values.</li></ul><h4 id="Worst-case-scenario"><a href="#Worst-case-scenario" class="headerlink" title="Worst case scenario"></a>Worst case scenario</h4><p><img src="http://static.zybuluo.com/sqfan/l5okgj5uwhlx4c9qcpuwb7jt/f-algorithm.gif" alt="f-algorithm.gif-145.7kB"></p><h2 id="Consensus-with-Byzantine-Failures"><a href="#Consensus-with-Byzantine-Failures" class="headerlink" title="Consensus with Byzantine Failures"></a>Consensus with Byzantine Failures</h2><blockquote><p><strong>Theorem (5.7)</strong>:  Any consensus algorithm for 1 Byzantine failure must have at least 4 processors.</p></blockquote><p>Proof of Theorem 5.7:<br><img src="http://static.zybuluo.com/sqfan/fggijnartoo9il036cnmmsee/image_1bven6g7d173d11ef12j8kvdiin34.png" alt="image_1bven6g7d173d11ef12j8kvdiin34.png-61.5kB"></p><blockquote><p><strong>Theorem</strong>:  Any consensus algorithm for <em>f</em> Byzantine failures must have at least <em>3f+1</em> processors.</p></blockquote><ul><li>Partition the processors into three sets P0, P1, P2;<ul><li>Each containing at most n/3 processors</li></ul></li><li>P0 simulates p0, P1 simulates p1 and P2 simulates p2</li><li>n processors solves consensus =&gt; {p0, p1, p2} solves consensus.  ==&gt; Contradiction.</li></ul><h2 id="Exponential-Information-Gathering-EIG-Algorithm"><a href="#Exponential-Information-Gathering-EIG-Algorithm" class="headerlink" title="Exponential Information Gathering (EIG) Algorithm"></a>Exponential Information Gathering (EIG) Algorithm</h2><p>This algorithm uses</p><ul><li>f + 1 rounds (optimal)</li><li>n = 3f + 1 processors (optimal)</li><li>exponential size messages (sub-optimal)</li></ul><p>Each processor keeps a tree data structure in its local state. Values are filled in the tree during the f + 1 rounds<br>At the end, the values in the tree are used to calculate the decision.</p><h3 id="Local-Tree-Data-Structure"><a href="#Local-Tree-Data-Structure" class="headerlink" title="Local Tree Data Structure"></a>Local Tree Data Structure</h3><ul><li>Each tree node is labeled with <strong>a sequence of</strong> unique processor indices.</li><li>Root’s label is empty sequence ; root has level 0</li><li>Root has <code>n</code> children, labeled 0 through n - 1</li><li>Child node labeled i has n - 1 children, labeled i : 0 through i : n-1 (<strong>skipping i : i</strong>)</li><li>Node at level <code>d</code> labeled <code>v</code> has <code>n - d</code> children, labeled v : 0 through v : n-1 (<strong>skipping any index appearing in v</strong>)</li><li>Nodes at level f + 1 are leaves.</li></ul><p>The tree when n = 4 and f = 1 :</p><p><img src="http://static.zybuluo.com/sqfan/joxki8ngdk011adx9codwgn7/image_1bveqt9ttg1pfv5qjv13h615cv7m.png" alt="image_1bveqt9ttg1pfv5qjv13h615cv7m.png-48.1kB"></p><h3 id="Filling-in-the-Tree-Nodes"><a href="#Filling-in-the-Tree-Nodes" class="headerlink" title="Filling in the Tree Nodes"></a>Filling in the Tree Nodes</h3><ul><li>Initially store your input in the root (level 0)</li><li>Round 1:  <ul><li>send level 0 of your tree to all</li><li>store value x received from each p_j in tree node labeled j (level 1); use a default if necessary</li><li>“pj told me that pj ‘s input was x”</li></ul></li><li>Round 2:<ul><li>send level 1 of your tree to all</li><li>store value x received from each pj for each tree node k in tree node labeled k : j (level 2); use a default if necessary</li><li>“pj told me that pk told pj that pk’s input was x”</li></ul></li><li>Continue for f + 1 rounds</li></ul><h3 id="Calculating-the-Decision"><a href="#Calculating-the-Decision" class="headerlink" title="Calculating the Decision"></a>Calculating the Decision</h3><ul><li>In round f + 1, each processor uses the values in its tree to compute its decision.</li><li><p>Recursively compute the “resolved” value for the root of the tree, <code>resolve()</code>, based on the “resolved” values for the other tree nodes:</p><p>  <img src="http://static.zybuluo.com/sqfan/hw0m0wv2ji8j69uweawp48pm/image_1bvepphnj1olttd012914ka1m8662.png" alt="image_1bvepphnj1olttd012914ka1m8662.png-14.8kB"></p></li></ul><p>Example of resolving values when n = 4 and f = 1:</p><p><img src="http://static.zybuluo.com/sqfan/6jwenw1oshgpwdg69okcj6qz/image_1bvepthlf1ipjgsuuea1qej14ko6f.png" alt="image_1bvepthlf1ipjgsuuea1qej14ko6f.png-34.9kB"></p><h2 id="A-Polynomial-Algorithm-The-King-Algorithm"><a href="#A-Polynomial-Algorithm-The-King-Algorithm" class="headerlink" title="A Polynomial Algorithm (The King Algorithm)"></a>A Polynomial Algorithm (The King Algorithm)</h2><p>We can reduce the message size to polynomial with a simple algorithm.</p><ul><li>The number of processors increases to: n &gt; 4f</li><li>The number of rounds increases to 2(f + 1)</li><li>Uses f+1 phases, each taking two rounds.</li></ul><p><img src="http://static.zybuluo.com/sqfan/imhi1feobwcw0fvkt1i1brbb/image_1bveqb3lk1gdip7m1mnu1a791j6a79.png" alt="image_1bveqb3lk1gdip7m1mnu1a791j6a79.png-106kB"></p><h2 id="Asynchronous-Consensus"><a href="#Asynchronous-Consensus" class="headerlink" title="Asynchronous Consensus"></a>Asynchronous Consensus</h2><p>Assumptions</p><ul><li>Communication system is reliable</li><li>Only processor failures (crash / Byzantine)</li><li>Completely asynchronous</li></ul><blockquote><p><strong>Theorem</strong>: For n ≥ 2, there is no algorithm in the read/write shared memory model that solves the agreement problem and guarantees wait-free termination</p></blockquote><p><code>Consensus is impossible</code>!!!</p><ul><li>Even in the presence of one single<br>processor (crash) failure</li></ul><p>Proof of impossibility</p><ul><li>Impossibility for shared memory<ul><li>The (n-1)-resilient case (wait-free case)</li><li>The 1-resilient case</li></ul></li><li>Impossibility for message passing <ul><li>Simulation</li></ul></li><li>Impossibility motivates the use of <code>failure detectors</code>.<ul><li>E.g., “The weakest failure detector for solving consensus”, JACM 43(4).</li></ul></li></ul><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>Let f be the maximum number of faulty processors.</p><p><img src="http://static.zybuluo.com/sqfan/19nqclsounkyu7x122nfsvow/image_1bvesf5cr18v9imp1b2l19cbkp2aq.png" alt="image_1bvesf5cr18v9imp1b2l19cbkp2aq.png-45.2kB"></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="http://hagit.net.technion.ac.il/publications/dc/" target="_blank" rel="external">Attiya, Hagit, and Jennifer Welch. <strong>Distributed computing</strong>: fundamentals, simulations, and advanced topics. Vol. 19. John Wiley &amp; Sons, 2004.</a>.<br>[2] <a href="https://www.youtube.com/watch?v=_e4wNoTV3Gw&amp;index=6&amp;list=PLOE1GTZ5ouRPbpTnrZ3Wqjamfwn_Q5Y9A" target="_blank" rel="external">Byzantine Fault Tolerance, Distributed System (A free online class), by Chris Colohan</a>.<br>[3] The Byzantine Generals Problem, Leslie Lamport, Robert Shostack and Mashall Peace.  ACM TOPLAS 4.3, 1982.<br>[4] <a href="https://parasol.tamu.edu/~welch/teaching/668.s14/" target="_blank" rel="external">CSCE 668: Distributed Algorithms and Systems Spring 2014</a>.</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The consensus problem&lt;/li&gt;
&lt;li&gt;Consensus with Byzantine Failures&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Introduction to Distributed Algorithms" scheme="http://fanshiqing.github.io/categories/Introduction-to-Distributed-Algorithms/"/>
    
    
      <category term="分布式算法" scheme="http://fanshiqing.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>L04-Mutual Exclusion</title>
    <link href="http://fanshiqing.github.io/2017/10/19/L04-Mutual-Exclusion/"/>
    <id>http://fanshiqing.github.io/2017/10/19/L04-Mutual-Exclusion/</id>
    <published>2017-10-19T06:35:55.000Z</published>
    <updated>2017-11-15T08:48:05.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h2><ul><li>The MUTEX problem<ul><li>the shared memory model</li><li>problem definition</li></ul></li><li>The unbounded algorithm<ul><li>The <strong>bakery algorithm</strong></li></ul></li><li>The unbounded algorithm</li></ul><a id="more"></a><h2 id="Shared-Memory-Model"><a href="#Shared-Memory-Model" class="headerlink" title="Shared Memory Model"></a>Shared Memory Model</h2><p>Processes communicate via a set of <strong>shared variables</strong> (also called <strong>shared registers</strong>), each shared variable has a <strong>type</strong>, defining a set of primitive operations (performed <code>atomically</code>)</p><p><img src="http://static.zybuluo.com/sqfan/wn08syzyz5d39z9hsf6n9f9w/image_1busp6ur1kh31rf41r7t12kl1kd66h.png" alt="image_1busp6ur1kh31rf41r7t12kl1kd66h.png-17.6kB"></p><p>Several types of shared variable can be employed, e.g.</p><ul><li>read/write</li><li>read-modify-write (RMW)</li><li>compare&amp;swap (CAS)</li></ul><p>Each register has a type, which specifies:</p><ul><li>Values to be taken on by registers</li><li>Operations performed on the registers</li><li>Values to be returned by operations (if any)</li><li>New values of the register resulting from the operation</li></ul><p>A <code>configuration</code> in the shared memory model is a vector: C = </p><p><img src="http://static.zybuluo.com/sqfan/qx9eqklt61x6x8p4nh5wzxyn/image_1buspq3steuh1t3n1r031h7o1ufb6u.png" alt="image_1buspq3steuh1t3n1r031h7o1ufb6u.png-14kB"></p><p>where q_i is a state of p_i and r_j is a value of register R.</p><p>The <code>events</code> in a shared memory system are:</p><ul><li>computation steps taken by the processors and are denoted by the index of the processor;</li><li>At each computation step, the shared variable is accessed.</li></ul><p>In asynchronous shared memory systems, an execution is <code>admissible</code> if each processor has an infinite number of computation steps.</p><h3 id="Complexity-measures"><a href="#Complexity-measures" class="headerlink" title="Complexity measures"></a>Complexity measures</h3><p>Obviously in shared memory systems there are no messages to measure. Instead we focus on the <code>space complexity</code>, the amount of shared memory needed to solve problems.</p><ul><li>Number of distinct shared variables required</li><li>and the amount of shared space (e.g., # of bits)</li></ul><h3 id="Changes-from-the-MSG-model"><a href="#Changes-from-the-MSG-model" class="headerlink" title="Changes from the MSG model"></a>Changes from the MSG model</h3><ul><li>Communication medium changes<ul><li>No inbuf and outbuf state components</li><li>Configuration includes values for shared variables</li></ul></li><li>Execution manner changes<ul><li>One event type: one computation step by a process<ul><li>pi’s state in old configuration specifies which shared variable is to be accessed and with which primitive</li><li>shared variable’s value in the new configuration changes according to the primitive’s semantics</li><li>pi’s state in the new configuration changes according to its old state and the result of the primitive</li></ul></li></ul></li></ul><h2 id="The-Mutual-Exclusion-Problem"><a href="#The-Mutual-Exclusion-Problem" class="headerlink" title="The Mutual Exclusion Problem"></a>The Mutual Exclusion Problem</h2><p>Each processor’s code is divided into four sections:</p><p><img src="http://static.zybuluo.com/sqfan/9a3ylq2nc360x9qn90v2uj6c/image_1buvcdt98c3u18sea2qpgp1funda.png" alt="image_1buvcdt98c3u18sea2qpgp1funda.png-13.1kB"></p><ul><li><code>Entry (trying)</code>: the code executed in preparation for entering the critical section</li><li><code>Critical</code>: the code to be protected from concurrent execution</li><li><code>Exit</code> (release): the code executed on leaving the critical section</li><li><code>Remainder</code>: the rest of the code</li></ul><p>Each processor cycles through these sections in the order: remainder –&gt; entry –&gt; critical –&gt; exit –&gt; remainder.</p><p>An algorithm for a shared memory system solves the <code>mutual exclusion</code> problem with no deadlock (or no lockout) if the following holds (three properties):</p><ul><li><code>Mutual exclusion</code>: In every configuration of every execution, at most one processor is in the critical section.</li><li><code>No deadlock</code>: In every admissible execution, if some processor is in the <strong>entry section</strong> in a configuration, then there is a later configuration in which <strong>some</strong> processor is in the critical section.</li><li><code>No lockout</code>: In every admissible execution, if some processor is in the <strong>entry section</strong> in a configuration, then there is a later configuration in which <strong>that same</strong> processor is in the critical section.</li></ul><p>Mutex progress conditions:</p><ul><li>no deadlock</li><li>no lockout</li><li><code>bounded waiting</code>: no lockout + <strong>while a processor is in its entry section, other processors enter the critical section no more than a certain number of times</strong>.</li></ul><p><strong>These three conditions are increasingly strong.</strong></p><p>The code for the entry and exit sections is allowed to assume that:</p><ul><li>no processor stays in its critical section forever</li><li>shared variables used in the entry and exit sections are not accessed during the critical and remainder sections</li></ul><h2 id="Mutual-Exclusion-Using-Powerful-Primitives"><a href="#Mutual-Exclusion-Using-Powerful-Primitives" class="headerlink" title="Mutual Exclusion Using Powerful Primitives"></a>Mutual Exclusion Using Powerful Primitives</h2><p>We will show that</p><ul><li><strong>one bit</strong> suffices for guaranteeing mutual exclusion with no deadlock</li><li>while <strong>O(logn)</strong> bits are necessary (and sufficient) for providing stronger fairness properties.</li></ul><h3 id="Binary-Test-amp-Set-Registers"><a href="#Binary-Test-amp-Set-Registers" class="headerlink" title="Binary Test&amp;Set  Registers"></a>Binary Test&amp;Set  Registers</h3><p>The <code>test&amp;set</code> operation <strong>atomically</strong> reads and updates the variable.</p><p><img src="http://static.zybuluo.com/sqfan/picjprmbz1mbyyz208r4p5x5/image_1but75uk01ess19052u2137912u87o.png" alt="image_1but75uk01ess19052u2137912u87o.png-18.8kB"></p><p>There is a simple mutual exclusion algorithm with no deadlock that uses one <code>test&amp;set</code> register(Algorithm 7).</p><p><img src="http://static.zybuluo.com/sqfan/77k1nnayun5530ikaodbasbx/image_1but7idl41nh27an18jv15541opb8i.png" alt="image_1but7idl41nh27an18jv15541opb8i.png-28.8kB"></p><ul><li>One processor could always grab V (i.e., win the test&amp;set competition) and starve the others. </li><li>No Lockout does not hold. </li><li>Thus Bounded Waiting does not hold.</li></ul><h3 id="Read-Modify-Write-Registersz"><a href="#Read-Modify-Write-Registersz" class="headerlink" title="Read-Modify-Write Registersz"></a>Read-Modify-Write Registersz</h3><p>The <code>RMW</code> operation read-modify-write <strong>all in one atomic operation</strong>.<br>Clearly, the <code>test&amp;set</code> operation is a special case of <code>rmw</code>, where f(V) = 1 for any V.<br><img src="http://static.zybuluo.com/sqfan/f2osslvatwb30n0pua4c8wo5/image_1but76ho2njp1kuvp1t1ujv1fki85.png" alt="image_1but76ho2njp1kuvp1t1ujv1fki85.png-13kB"></p><p><img src="http://static.zybuluo.com/sqfan/u54fzf0r8pav05wuv0nopeqh/image_1but836531d6418131m9isfn12h8v.png" alt="image_1but836531d6418131m9isfn12h8v.png-48.3kB"><br>Detailed analysis about algorithm 8 please refer to the textbook.</p><hr><h2 id="Mutual-Exclusion-Using-Read-Write-Registers"><a href="#Mutual-Exclusion-Using-Read-Write-Registers" class="headerlink" title="Mutual Exclusion Using Read/Write Registers"></a>Mutual Exclusion Using Read/Write Registers</h2><h3 id="The-Bakery-Algorithm"><a href="#The-Bakery-Algorithm" class="headerlink" title="The Bakery Algorithm"></a>The Bakery Algorithm</h3><p>Basic idea:</p><ul><li>Tell others “I want to enter the critical section”</li><li>Get tickets and wait for my turn</li></ul><p>We employ the following shared data structures:</p><ul><li><code>Number</code>: an array of n integers, which holds in its ith entry the number of p_i</li><li><code>Choosing</code>: an array of n Boolean values; Choosing[i] is <code>true</code> while p_i is in the process of obtaining its number.</li></ul><p>Because several processors can read <code>Number</code> concurrently it is possible for several procesors to obtain the same number!.</p><p>To break symmetry, we define <code>p_i&#39;s ticket</code> be the pair <code>(Number[i], i)</code> （uniqueness）(tickets之间的序比较可以使用字典序). </p><p><img src="http://static.zybuluo.com/sqfan/tdv2dfbu3ltig8y99gjxgdhk/image_1but8u55uj361l3m1qh5em71qvc9s.png" alt="image_1but8u55uj361l3m1qh5em71qvc9s.png-44.6kB"></p><p>Algorithm 10 provides mutual exclusion and no lockout. (proof pls refer to the textbook)</p><p>The numbers can <strong>grow without bound</strong>, unless when every processor is in the remainder section.</p><blockquote><p>How to achieve MUTEX when variables have finite size.</p></blockquote><h3 id="A-Bounded-Mutual-Exclusion-Algorithm-for-2-Processors"><a href="#A-Bounded-Mutual-Exclusion-Algorithm-for-2-Processors" class="headerlink" title="A Bounded Mutual Exclusion Algorithm for 2 Processors"></a>A Bounded Mutual Exclusion Algorithm for 2 Processors</h3><p><code>Algorithm 11</code> provides mututual exclusion and no deadlock for two processors p_0 and p_1. Each processor p_i has a Boolean shared variable <code>Want[i]</code>.</p><ul><li>Want[i]=1: if p_i wants to enter the critical section.</li></ul><p>However, the algorithm gives <strong>prioirty</strong> to one of the processors and the other one can <code>starve</code>.</p><p><img src="http://static.zybuluo.com/sqfan/1r7ll2awo5aubcelhlwicgnm/image_1butan78f14791ir1h7ot2f1ih1a9.png" alt="image_1butan78f14791ir1h7ot2f1ih1a9.png-54.2kB"></p><p>We then convert this algorithm to one that provides no lockout as well.<br>To achieve no lockout, we modify the alrgorithm so that instead of always giving priority to p_0, each processor gives priority to the other processor on leaving the critical section.</p><ul><li><code>Priority</code>: <strong>Shared variable</strong>, contains the id of the processor that has the priority at the moment.</li></ul><p>In the entry, wait until:</p><ul><li>Case 1: the other processor has the priority (but does not want to enter the critical section)</li><li><p>Case 2: I have the priority.</p><p>  <img src="http://static.zybuluo.com/sqfan/9yl17tapp29nu8oxbqc2tfxu/image_1butanrpuomi9ru1je1101o1pooam.png" alt="image_1butanrpuomi9ru1je1101o1pooam.png-76.4kB"></p></li></ul><h3 id="A-Bounded-Mutual-Exclusion-Algorithm-for-n-Processors-recursively-use-the-2-no-lockout-algorithm"><a href="#A-Bounded-Mutual-Exclusion-Algorithm-for-n-Processors-recursively-use-the-2-no-lockout-algorithm" class="headerlink" title="A Bounded Mutual Exclusion Algorithm for n Processors (recursively use the [2, no lockout] algorithm)"></a>A Bounded Mutual Exclusion Algorithm for n Processors (recursively use the [2, no lockout] algorithm)</h3><p>To construct a solution for the general case of <code>n</code> processors we <strong>employ the algorithm for two processors</strong>.</p><ul><li>Proceessors compete pairwise, using the two-processor algorithm described above, in a <code>tournament tree</code> (锦标赛树) arrangement.</li><li>The pairwise competitions are arranged in a complete binary tree.</li><li>Each processor begins at a specific leaf of the tree.</li><li>At each level, the winner gets to proceed to the next higher level, where it competes with the winner of the competition on the other side of the tree.</li><li><strong>The processor that wins at the root enters the critical section</strong>.</li></ul><p><img src="http://static.zybuluo.com/sqfan/knpj6h460t7gmkxllgi15jqj/image_1butapds11jguce1nt31dtp1q1qb3.png" alt="image_1butapds11jguce1nt31dtp1q1qb3.png-17.7kB"></p><ul><li><code>v</code>: node number; we associate shared variable <code>Want^v[0]</code>, <code>Want^v[1]</code>, and <code>Priority^v</code> (all initialized to 0)</li><li><p>To begin the competition for the (real) critical section, processor <code>p_i</code> executes <code>Node(2^k + i/2, i mod 2)</code></p><ul><li>note that the leaves of the tree are numbered 2^k, 2^k + 1, …, 2^(k+1) - 1 (see Fig. 4.7). </li><li><p>the processor on the left (right) side play the role of p_0 (p_1)</p><p><img src="http://static.zybuluo.com/sqfan/cm23hvnk0z7iihjtb8jvkayu/image_1butapvs01k681mh31j781dti6a9bg.png" alt="image_1butapvs01k681mh31j781dti6a9bg.png-56.2kB"></p></li></ul></li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="http://hagit.net.technion.ac.il/publications/dc/" target="_blank" rel="external">Attiya, Hagit, and Jennifer Welch. <strong>Distributed computing</strong>: fundamentals, simulations, and advanced topics. Vol. 19. John Wiley &amp; Sons, 2004.</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;The MUTEX problem&lt;ul&gt;
&lt;li&gt;the shared memory model&lt;/li&gt;
&lt;li&gt;problem definition&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The unbounded algorithm&lt;ul&gt;
&lt;li&gt;The &lt;strong&gt;bakery algorithm&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;The unbounded algorithm&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Introduction to Distributed Algorithms" scheme="http://fanshiqing.github.io/categories/Introduction-to-Distributed-Algorithms/"/>
    
    
      <category term="分布式算法" scheme="http://fanshiqing.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>L03-Leader Election in Rings</title>
    <link href="http://fanshiqing.github.io/2017/10/12/L03-Leader-Election-in-Rings/"/>
    <id>http://fanshiqing.github.io/2017/10/12/L03-Leader-Election-in-Rings/</id>
    <published>2017-10-12T13:16:03.000Z</published>
    <updated>2017-11-13T06:39:24.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Discuss the leader election (LE) problem in message-passing systems for a ring topology, in which a group of processors must choose one among them to be a leader.</li><li>Present the different algorithms for leader election problem by taking the cases like anonymous/non-anonymous rings, uniform/non-uniform rings and synchronous/asynchronous rings etc.</li></ul><a id="more"></a><p>[Based on the book “<strong>Distributed Computing</strong>“ by Hagit attiya &amp; Jennifer Welch]</p><h2 id="Ring-Networks"><a href="#Ring-Networks" class="headerlink" title="Ring Networks"></a>Ring Networks</h2><p><img src="http://static.zybuluo.com/sqfan/qtrrif1ta6opgr54rx5071ij/image_1bue05vdhcjd1eb9rnt4do2spm.png" alt="image_1bue05vdhcjd1eb9rnt4do2spm.png-15.7kB"></p><ul><li>In an <code>oriented ring</code>, processors have a consistent notion of left and right.<ul><li>For example, if messages are always forwarded on <code>channel 1</code>, they will cycle clockwise around the ring.</li></ul></li></ul><blockquote><p>Why study rings?</p><ul><li>simple starting point, easy to analyze</li><li>abstraction of a token ring</li><li>lower bounds and impossibility results for ring topology also apply to arbitrary topoligies.</li></ul></blockquote><h2 id="The-Leader-Election-LE-Problem"><a href="#The-Leader-Election-LE-Problem" class="headerlink" title="The Leader Election (LE) Problem"></a>The Leader Election (LE) Problem</h2><ul><li>LE problem is for each processor to decide that either it is <strong>the leader or non-leader</strong>, subject to the constraint that exactly one processor decides to be the leader.</li><li>LE problem represents a general class of <strong>symmetry-breaking</strong> problems.<ul><li>For example, when a <code>deadlock</code> is created, because of processors waiting in a cycle for each other, the deadlock can be broken by electing one of the processor as a leader and removing it from the cycle. </li></ul></li><li>Each processor has a set of <code>elected (won)</code> and <code>not-elected (lost)</code> states.</li><li>Once an elected state is entered, processor is always in an elected state (and similarly for not-elected): i.e., irreversible decision.</li><li>In every admissible execution:<ul><li>every processor eventually enters an elected or a not-elected state</li><li>exectly one processor (the <code>leader</code>) enters an elected state.</li></ul></li></ul><h3 id="Uses-of-LE"><a href="#Uses-of-LE" class="headerlink" title="Uses of LE"></a>Uses of LE</h3><ul><li>A leader can be used to coordinate activities of the system:<ul><li>find a <code>spanning tree</code> using the leader as the root;</li><li>reconstruct a <code>lost token</code> in a token-ring network.</li></ul></li></ul><h2 id="Uniform-Anonymous-Algorithms"><a href="#Uniform-Anonymous-Algorithms" class="headerlink" title="Uniform (Anonymous) Algorithms"></a>Uniform (Anonymous) Algorithms</h2><ul><li><code>Anonymous or not</code>: A leader election algorithm is anonymous if processors do not have unique identifiers that can be used by the algorithm<ul><li>Message recipients can only be specified in terms of channel labels, e.g., left and right neighbors </li><li>==&gt; Every processor in the system has the same state machine.</li></ul></li><li>A <code>uniform</code> algorithm does not use the ring size (same algorithm for each size ring)<ul><li>Formally, every processor in every size ring is modeled with the same state machine</li><li>Uniform: since the algorithm looks the same for every value of n.</li></ul></li><li>A <code>non-uniform</code> algorithm uses the ring size (different algorithm for each size ring)<ul><li>Formally, for each value of n, every processor in a ring of size n is modeled with the same state machine An .</li></ul></li></ul><h2 id="Leader-Election-in-Anonymous-Rings"><a href="#Leader-Election-in-Anonymous-Rings" class="headerlink" title="Leader Election in Anonymous Rings"></a>Leader Election in Anonymous Rings</h2><p><code>Theorem:</code> <strong>For nonuniform algorithms and synchronous rings, there are no anonymous LE algorithms</strong>.</p><p>Proof Sketch:</p><ul><li>Every processor begins in same state with same outgoing msgs (since anonymous)</li><li>Every processor receives same msgs, does same state transition, and sends same msgs in round 1</li><li>Ditto for rounds 2,3,…</li><li>Eventually some processor is supposed to enter an elected state.  But then they all would.</li></ul><p>Proof sketch shows that either <strong>safety</strong> (never elect more than one leader) or <strong>liveness</strong> (eventually elect at least one leader) is violated. Since the theorem was proved for non-uniform and synchronous rings, the same result holds for weaker (less well-behaved) models (uniform / asynchronous).</p><p><img src="http://static.zybuluo.com/sqfan/rveobgknzovji6jdsubae73v/image_1bug0fadc1e523b21fn7uqu1qn830.png" alt="image_1bug0fadc1e523b21fn7uqu1qn830.png-95.2kB"></p><blockquote><p><a href="https://en.wikipedia.org/wiki/Lattice_(order" target="_blank" rel="external">Lattice</a>) (格）<br>A lattice is an abstract structure studied in the mathematical subdisciplines of order theory and abstract algebra. It consists of a partially ordered set in which every two elements have a unique supremum (上确界) (also called a least upper bound or <strong>join</strong>, a ∧ b) and a unique infimum （下确界）(also called a greatest lower bound or <strong>meet</strong>, a V b)</p></blockquote><p>Based on the impossibility result, we can reasonably assume that: <code>Rings with unique processor identifiers</code>.</p><h2 id="LE-in-Asynchronous-Rings"><a href="#LE-in-Asynchronous-Rings" class="headerlink" title="LE in Asynchronous Rings"></a>LE in Asynchronous Rings</h2><p>There exists algorithms when nodes have unique ids. We will evaluate them according to their <em>message complexity</em>.</p><h3 id="Brute-Force-LE"><a href="#Brute-Force-LE" class="headerlink" title="Brute Force LE"></a>Brute Force LE</h3><p><img src="http://static.zybuluo.com/sqfan/a2iw6dqxfppfi3o06tm3cftr/image_1bug5niima1fh3so2m1uua1jdp3d.png" alt="image_1bug5niima1fh3so2m1uua1jdp3d.png-16.1kB"><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">Send value of own id to the left.</div><div class="line"></div><div class="line">When receive an id j (from the right)</div><div class="line">    if j &gt; id then</div><div class="line">        forward j to the left // this processor has lost</div><div class="line">    if j == id then</div><div class="line">        elect self // this processor has won</div><div class="line">    if j &lt; id then</div><div class="line">        // do nothing (swallow)</div></pre></td></tr></table></figure></p><h4 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h4><ul><li><strong>Correctness</strong>: Elect processor with the largest id. (Time: O(n))</li><li><strong>Message complexity</strong>: Depends on how the ids are arranged.<ul><li>largest id travels all around the ring (n msgs)</li><li>2nd largest id travels until reaching largest</li><li>3rd largest id travels until reaching largest or second largest.</li><li>etc.</li><li>Worst way to arrange the ids is in decreasing order (Fig.3.2)</li></ul></li></ul><p>The O(n^2) algorithm is simple and works in both sync and async model. But how to optimize?</p><blockquote><p><strong>Idea</strong>: try to have message containing smaller ids travel smaller distance in the ring.</p></blockquote><h3 id="k-neighbour-Forwarding"><a href="#k-neighbour-Forwarding" class="headerlink" title="k-neighbour Forwarding"></a>k-neighbour Forwarding</h3><ul><li>Basic idea<ul><li>Gradually increase the scope of sending</li><li>Eliminate unnecessary senders accordingly</li><li>Smaller IDs are swallowed</li></ul></li><li>Clever forwarding<ul><li>k-neighbourhood<ul><li>2k+1 nodes: k left + k right + self</li></ul></li><li>in the kth phase, LE among the 2^k-neighborhood<ul><li>size of neighbourhood <strong>doubles</strong> in each phase</li><li>only the winner survives to the next phase</li></ul></li></ul></li></ul><p><img src="http://static.zybuluo.com/sqfan/faxuqz0jm6fxsyxjj6w9qd1m/image_1bug88k2j1tj7109p19ll12e096b4a.png" alt="image_1bug88k2j1tj7109p19ll12e096b4a.png-197kB"></p><h4 id="Analysis-1"><a href="#Analysis-1" class="headerlink" title="Analysis"></a>Analysis</h4><ul><li>Correctness: similar to O(n*2) algorithm</li><li><strong>Message complexity</strong><ul><li>Each msg belongs to a particular phase and is initiated by a particular proc.</li><li>Probe distance in phase k is 2^k</li><li>Number of msgs initiated by a proc. in phase k is at most <strong>4</strong> * 2^k (probes and replies in both directions)</li><li>How many proc. initiate probes in phase <em>k</em> ?<ul><li>For k = 0, every proc. does</li><li>For k &gt; 0, every proc. that is a “winner” in previous phase (phase <strong>k-1</strong>) does</li></ul></li><li>Maximum number of phase <strong>k-1</strong> winners occurs when the are packed as densely as possible:<br><img src="http://static.zybuluo.com/sqfan/vl3eiohzz0fj2zt1y8g2y8yc/image_1bugc8ue119cphe614og1qjv1qrk4n.png" alt="image_1bugc8ue119cphe614og1qjv1qrk4n.png-12.5kB"></li><li>Total number of phase k-1 winners is at most <strong>n/(2^(k-1) + 1)</strong></li><li>How many phases are there?<ul><li>let <strong>n/2^(k-1) + 1 == 1</strong> (at the last phase there exists only one winner) ==&gt; <strong>k = log(n-1) + 1</strong> = number of phases</li></ul></li></ul></li></ul><p>So the total number of msgs is sum, over all phases, of number of winners at that phase <em>times</em> number of msgs originated by that winner:<br><img src="http://static.zybuluo.com/sqfan/fxnyl4pjmr8co6i8hh5onfz0/image_1bugd4jjg1kvm1ff117bbo541k1l54.png" alt="image_1bugd4jjg1kvm1ff117bbo541k1l54.png-25.7kB"></p><p>The O(log n) algorithm is more complicated than the O(n^2) algorithm but uses fewer messages in worst case.</p><h2 id="Lower-bound-for-LE-Algorithm"><a href="#Lower-bound-for-LE-Algorithm" class="headerlink" title="Lower bound for LE Algorithm"></a>Lower bound for LE Algorithm</h2><p>Can we do better than O(nlogn) ?</p><p><code>Theorem</code>: Any leader election algorithm for <strong>asynchronous</strong> rings whose size is not known a priori has Ω(nlog n) msg complexity (holds also for undirectional rings).</p><ul><li>The two algorithms above are <strong>comparison-based</strong> algorithms, i.e. they use the identifiers only for comparison (&lt;, &gt;, =)</li><li>In synchronous networks, O(n) msg complexity can be achieved if general arithmatic operations are permitted (<strong>non-comparison based</strong>) and if time complexity is unbounded.</li></ul><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="http://hagit.net.technion.ac.il/publications/dc/" target="_blank" rel="external">Attiya, Hagit, and Jennifer Welch. <strong>Distributed computing</strong>: fundamentals, simulations, and advanced topics. Vol. 19. John Wiley &amp; Sons, 2004.</a><br>[2] <a href="http://www.bigoh.net/wiki/index.php/Dis-alg" target="_blank" rel="external">分布式算法（黄宇）课程主页</a><br>[3] <a href="https://www.youtube.com/watch?v=LRUcPNet6i4" target="_blank" rel="external">Distributed System</a></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;Discuss the leader election (LE) problem in message-passing systems for a ring topology, in which a group of processors must choose one among them to be a leader.&lt;/li&gt;
&lt;li&gt;Present the different algorithms for leader election problem by taking the cases like anonymous/non-anonymous rings, uniform/non-uniform rings and synchronous/asynchronous rings etc.&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Introduction to Distributed Algorithms" scheme="http://fanshiqing.github.io/categories/Introduction-to-Distributed-Algorithms/"/>
    
    
      <category term="分布式算法" scheme="http://fanshiqing.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>L02-Basic Message Passing Algorithms</title>
    <link href="http://fanshiqing.github.io/2017/10/05/L02-Basic-Message-Passing-Algorithms/"/>
    <id>http://fanshiqing.github.io/2017/10/05/L02-Basic-Message-Passing-Algorithms/</id>
    <published>2017-10-05T08:23:50.000Z</published>
    <updated>2017-11-13T06:42:16.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Broadcast / convergecast on a spanning tree</li><li>Async / sync flooding to construct a spanning tree</li><li>distributed DFS with/without a specific root</li></ul><a id="more"></a><h2 id="Broadcast-over-a-rooted-spanning-tree"><a href="#Broadcast-over-a-rooted-spanning-tree" class="headerlink" title="Broadcast over a rooted spanning tree"></a>Broadcast over a rooted spanning tree</h2><ul><li>Broadcast is used to send the information to all.</li><li>Suppose processors <strong>already have information about a rooted spanning tree of the communication topology</strong><ul><li>tree: connected graph with no cycles</li><li>spanning tree: contains all processors</li><li>rooted: there is a unique root node</li></ul></li><li>Implemented via <code>parent</code> and <code>children</code> local varialbes at each processor.<ul><li>indicate which incident channnels lead to parent and children in the rooted spanning tree. </li></ul></li></ul><p><img src="http://static.zybuluo.com/sqfan/digj1gg45grlsp7yqlbxy387/image_1bu5gq7v33lgv161mc1lef1g9t9.png" alt="image_1bu5gq7v33lgv161mc1lef1g9t9.png-186.6kB"></p><blockquote><p><strong><a href="https://en.wikipedia.org/wiki/Spanning_tree" target="_blank" rel="external">Spanning Tree</a></strong>: A tree is a connected undirected graph with no cycles. It is a spanning tree of a graph G if it <strong>spans</strong> G (that is, it <code>includes every vertex of G</code>) and <code>is a subgraph of G</code> (every edge in the tree belongs to G). A spanning tree of a connected graph G can also be defined as a maximal set of edges of G that contains no cycle, or as a minimal set of edges that connect all vertices.</p></blockquote><p>Complexity analysis:</p><ul><li>Synchronous model<ul><li>Time complexity: time is depth <code>d</code> of the spanning tree. (at most <code>n-1</code> when chain)</li><li>MSG complexity: number of messages is <code>n-1</code>, since one message is sent over each spanning tree edges.</li></ul></li><li>Aysnchronous model<ul><li>Same as synchronous model. </li></ul></li></ul><h2 id="Convergecast-from-leaves-to-the-root"><a href="#Convergecast-from-leaves-to-the-root" class="headerlink" title="Convergecast (from leaves to the root)"></a>Convergecast (from leaves to the root)</h2><ul><li>Convergecast is used to collect the information.</li><li>Again, suppose a rooted spanning tree has already been computed by the processors<ul><li><em>parent</em> and <em>children</em> variables at each processor</li></ul></li><li>Do the opposite of broadcast<ul><li>leaves send msgs to their parents.</li><li>non-leaves wait to get msgs from each child, then send <strong>combined</strong> (aggregate) info to parent.</li></ul></li></ul><h2 id="Finding-a-Spanning-Tree-Given-a-Root-by-Flooding"><a href="#Finding-a-Spanning-Tree-Given-a-Root-by-Flooding" class="headerlink" title="Finding a Spanning Tree Given a Root by Flooding"></a>Finding a Spanning Tree Given a Root by Flooding</h2><blockquote><p><a href="https://en.wikipedia.org/wiki/Flooding_(computer_networking" target="_blank" rel="external">Flooding</a>): Flooding is a simple computer network routing algorithm in which every incoming packet is sent through every outgoing link except the one it arrived on.</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/Flooding_routing.gif/220px-Flooding_routing.gif" alt="flooding"></p></blockquote><ul><li>root send <em>M</em> to all its neighbours</li><li>when non-root first gets <em>M</em>,<ul><li>set the sender as its parent</li><li>send “parent” msg to sender</li><li>send <em>M</em> to all other neighbours (if no other neighours, then terminate)</li></ul></li><li>when get <em>M</em> otherwise,<ul><li>send “reject” to sender.</li></ul></li><li>use “parent” and “reject” msgs to set <em>children</em> varialbes and know when to terminate (after hearing from all neighbours)</li></ul><p><img src="http://static.zybuluo.com/sqfan/xdwf7bfg97pumdx3j45v8trt/image_1bu5ifmh212aq1a9oauomuchdn16.png" alt="image_1bu5ifmh212aq1a9oauomuchdn16.png-83.1kB"></p><p>Execution of spanning tree algorithm</p><ul><li>In the synchronous model: always gives breadth-first search (BFS) tree.</li><li>Asynchronous: not necessarily BFS tree. </li></ul><p>Both models achieves O(m) messages complexity and O(diam) time complexity.</p><blockquote><p><strong>Diameter <code>D</code> of a network</strong> is defined as the longest path of the shortest paths between any two nodes.</p></blockquote><h2 id="Distributed-DFS-with-a-Specified-Root"><a href="#Distributed-DFS-with-a-Specified-Root" class="headerlink" title="Distributed DFS with a Specified Root"></a>Distributed DFS with a Specified Root</h2><ul><li>Basic rationale: <strong>sequential execution</strong> over a distributed system (of multiple processors)</li></ul><p><img src="http://static.zybuluo.com/sqfan/6j4qhtilocj6kqjq3cusu57p/image_1bu5jha1n20n14gm0p1u3c198i20.png" alt="image_1bu5jha1n20n14gm0p1u3c198i20.png-281.1kB"></p><h2 id="Distributed-DFS-without-a-Specified-Root"><a href="#Distributed-DFS-without-a-Specified-Root" class="headerlink" title="Distributed DFS without a Specified Root"></a>Distributed DFS without a Specified Root</h2><ul><li>Assume <strong>the processors have unique identifiers</strong> (otherwise impossible!)</li><li>Idea:<ul><li>Each processor starts running a copy of the DFS spanning tree algorithm, with itself as root</li><li><strong>tag each msg with initiator’s id to differentiate</strong></li><li>when copies “collide”, copy with <code>larger id wins</code>.</li></ul></li><li>Message complexity: O(n*m)</li><li>Time complexity: O(m) (m: edges in graph)</li></ul><p><img src="http://static.zybuluo.com/sqfan/sb92i2ocjs27079je9k9axtg/image_1bu5k3agccbb1no917v3iak19gk2d.png" alt="image_1bu5k3agccbb1no917v3iak19gk2d.png-81kB"></p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="http://hagit.net.technion.ac.il/publications/dc/" target="_blank" rel="external">Attiya, Hagit, and Jennifer Welch. <strong>Distributed computing</strong>: fundamentals, simulations, and advanced topics. Vol. 19. John Wiley &amp; Sons, 2004.</a><br>[2] <a href="http://www.bigoh.net/wiki/index.php/Dis-alg" target="_blank" rel="external">分布式算法（黄宇）课程主页</a><br>[3] <a href="https://www.youtube.com/watch?v=kqTkbEgREYk" target="_blank" rel="external">Distributed System</a></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;Broadcast / convergecast on a spanning tree&lt;/li&gt;
&lt;li&gt;Async / sync flooding to construct a spanning tree&lt;/li&gt;
&lt;li&gt;distributed DFS with/without a specific root&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Introduction to Distributed Algorithms" scheme="http://fanshiqing.github.io/categories/Introduction-to-Distributed-Algorithms/"/>
    
    
      <category term="分布式算法" scheme="http://fanshiqing.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>L01-Model of Computation</title>
    <link href="http://fanshiqing.github.io/2017/09/27/L01-Model-of-Computation/"/>
    <id>http://fanshiqing.github.io/2017/09/27/L01-Model-of-Computation/</id>
    <published>2017-09-27T12:19:32.000Z</published>
    <updated>2017-11-13T06:46:23.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Async/sync system</li><li>Random access machine model</li><li>Message passing model</li><li>Shared memory model</li></ul><a id="more"></a><h2 id="Essential-Issues-of-Alogrithm"><a href="#Essential-Issues-of-Alogrithm" class="headerlink" title="Essential Issues of Alogrithm"></a>Essential Issues of Alogrithm</h2><ul><li>Model of computation</li><li>Algorithm design</li><li>Algorithm analysis</li></ul><h2 id="Asynchronous-amp-Synchronous-System"><a href="#Asynchronous-amp-Synchronous-System" class="headerlink" title="Asynchronous &amp; Synchronous System"></a>Asynchronous &amp; Synchronous System</h2><blockquote><p><strong>Asynchronous System</strong>. A system is said to be asynchronous if there is no fixed upper bound on how long it takes for a message to be delivered (message delays) or how much time elapses between consectutive steps of a processor (processor step time) [1].</p><p><strong>Synchronous System</strong>. In the synchronous model processors execute in lockstep: The execution is partitioned into rounds, and in each round, every processor can send a message to each neighbour, the messages are delivered, and every processor computes based on the messages just received. (This model is convenient for designing algorithms) [1]</p></blockquote><p><strong>Why asynchronous systems</strong>?</p><ul><li>Sometimes the upper bounds are quite large, are infrequently reached and change over time.</li><li>It is often desiable to design an algorithm that is <code>independent of any particular timing parameters</code>, namely an asynchronous algorithm<ul><li>Instead of design an algorithms that depends on the bounds </li></ul></li></ul><h2 id="Random-Access-Machine-RAM-Model"><a href="#Random-Access-Machine-RAM-Model" class="headerlink" title="Random Access Machine (RAM) Model"></a>Random Access Machine (<strong>RAM</strong>) Model</h2><p>The goal of working with a <strong>model</strong> computer instead of a <strong>real</strong> computer is that we want to have a machine, which is as easy as possible, but still let us capture the main aspects of a real computer.</p><p>This model of computation is an abstraction that allows us to <strong>compare algorithms on the basis of performance</strong>. Simplifications for RAM model:</p><ul><li>Simple operations take only 1 time step;</li><li>Loops and subroutines are not simple operations;</li><li>We assume we have as much memory as we need (<strong>infinite storage</strong>);</li><li>Memory access is considered to be free in terms of time (or one time step?);</li><li>A unit of memory cannot hold an arbitrarily large number. </li></ul><p><img src="http://static.zybuluo.com/sqfan/y88ifg3v7sobz4s4vdhvegub/image_1btlmrsqq14c81l3ks2f5j5n2b9.png" alt="RAM Model"><br>The RAM model takes no notice of whether an item is in cache or on the disk, which simplifies the analysis. It is an excellent model for understanding how an algorithm will perform on a real computer. It strikes a fine balance by <strong>capturing the essential behavior of computers while being simple to work with</strong>. We use the RAM model because it is useful in practice.</p><blockquote><p><strong>Relationship between the Turing Machine and RAM Models</strong><br>A random-access machine with unbounded indirection is equivalent to a Turing machine. Informally speaking, both machines have the same computational capabilities. (<a href="https://en.wikipedia.org/wiki/Random-access_machine#Turing_equivalence_of_the_RAM_with_indirection" target="_blank" rel="external">wikipedia</a> | <a href="https://www.youtube.com/watch?v=XhkXUHLVNtY" target="_blank" rel="external">Equivalance of RAM and Turing Machines</a>)</p></blockquote><h2 id="Message-Passing-Model"><a href="#Message-Passing-Model" class="headerlink" title="Message Passing Model"></a>Message Passing Model</h2><p>The architecture is used to communicate data among a set of processors without the need for a global memory. Each processor has its own local memory and communicates with other Processors using message.</p><p>Data exchanged among processors cannot be shared; it is rather <strong>copied</strong> (using send/receive messages). An important advantage of this form of data exchange is the elimination of the need for synchronization constructs, such as semaphores, which results in performance improvement.</p><hr><h2 id="Shared-Memory-Model"><a href="#Shared-Memory-Model" class="headerlink" title="Shared Memory Model"></a>Shared Memory Model</h2><p>Both SMP and DSM are <strong>shared address space</strong> platforms.</p><h3 id="Symmetric-Multiprocessors-SMP"><a href="#Symmetric-Multiprocessors-SMP" class="headerlink" title="Symmetric Multiprocessors (SMP)"></a>Symmetric Multiprocessors (SMP)</h3><p>Processors all connected to a large shared memory. Examples are processors connected by crossbar, or multicore chips. It is <strong>symmetric</strong> because the access time from any of the CPUs to memory is the same.</p><p>Key characteristics is <strong>uniform memory acess</strong> (UMA).<br><img src="http://static.zybuluo.com/sqfan/m94fg25wndazqj6t2xsudhkm/image_1btmomv42gua1lo01eoj5duvos9.png" alt="SMP"><br><strong>Caches</strong> are a problem: need to be kept coherrent = when one CPU changes a value in memory, then all other CPUs will get the same value when they access it. All caches will show a coherent value. </p><hr><h3 id="Distributed-Shared-Memory-DSM"><a href="#Distributed-Shared-Memory-DSM" class="headerlink" title="Distributed Shared Memory (DSM)"></a>Distributed Shared Memory (DSM)</h3><p>DSM is basically an abstraction that integrates the local memory of different machine into a single logical entity shared by cooperating processes.</p><ul><li>The distributed shared memory implements the shared memory model in distributed systems, which have no physical shared memory. (shared memory exists only virtually, similar concepts to virtual memory)</li><li>The shared memory model provides a <strong>virtual address space</strong> shared between all nodes</li><li>The overcome the high cost of communication in distributed systems, DSM systems move data to the location of access.</li></ul><p><img src="http://static.zybuluo.com/sqfan/9pay9edubua92wzyii7axxqw/image_1btmqsj1c17d9ltl4h1nmm7o13.png" alt="image_1btmqsj1c17d9ltl4h1nmm7o13.png-26.3kB"></p><p><img src="http://static.zybuluo.com/sqfan/0eed7sgn0qpo255jag7onj1o/image_1btmrqvvr9hs33n1rt619pe1sgv1g.png" alt="image_1btmrqvvr9hs33n1rt619pe1sgv1g.png-342.3kB"></p><p>How?</p><ul><li>Data moves between main memory and secondary memory (within a node) and between main memories of different nodes.</li><li>Each data object is owned by a node<ul><li>Initial owner is the node that created object</li><li>Ownership can change as object moves from node to node</li></ul></li><li>When a process accesses data in the shared address space, the mapping manager maps shared memory address to physical memory (local or remote). </li></ul><h2 id="Shared-Memory-v-s-Message-Passing"><a href="#Shared-Memory-v-s-Message-Passing" class="headerlink" title="Shared Memory v.s. Message Passing"></a><a href="https://www.youtube.com/watch?v=SmJpGl_PYz8" target="_blank" rel="external">Shared Memory v.s. Message Passing</a></h2><table><thead><tr><th></th><th>Messsge Passing</th><th>Shared Memory</th></tr></thead><tbody><tr><td>who does communication</td><td>Programmer</td><td>Automatic</td></tr><tr><td>Data distribution</td><td>Manual</td><td>Automatic</td></tr><tr><td>HW support</td><td>Simple</td><td>Extensive (automatically figures out when to send data, to whom and where to cache in, etc.)</td></tr><tr><td>Programming</td><td></td><td></td></tr><tr><td>Correctness</td><td>Difficult</td><td>Less Difficult</td></tr><tr><td>Performance</td><td>Difficult (noce you get correctness, performance is not far away)</td><td>Very Difficult</td></tr></tbody></table><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>[1] <a href="http://hagit.net.technion.ac.il/publications/dc/" target="_blank" rel="external">Attiya, Hagit, and Jennifer Welch. <strong>Distributed computing</strong>: fundamentals, simulations, and advanced topics. Vol. 19. John Wiley &amp; Sons, 2004.</a><br>[2] <a href="https://github.com/fanshiqing/Qix/blob/master/ds.md" target="_blank" rel="external">分布式系统(Distributed System)资料</a><br>[3] <a href="http://www.cs.nyu.edu/courses/fall10/G22.2945-001/slides/lect3-4.pdf" target="_blank" rel="external">Shared Memory, NYU Computer Science</a><br>[4] <a href="http://www.bigoh.net/wiki/index.php/Dis-alg" target="_blank" rel="external">分布式算法（黄宇）课程主页</a><br>[5] <a href="https://www.youtube.com/watch?v=SmJpGl_PYz8" target="_blank" rel="external">Message Passing Vs Shared Memory - Georgia Tech - HPCA: Part 5</a></p>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;Async/sync system&lt;/li&gt;
&lt;li&gt;Random access machine model&lt;/li&gt;
&lt;li&gt;Message passing model&lt;/li&gt;
&lt;li&gt;Shared memory model&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Introduction to Distributed Algorithms" scheme="http://fanshiqing.github.io/categories/Introduction-to-Distributed-Algorithms/"/>
    
    
      <category term="分布式算法" scheme="http://fanshiqing.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>htop - interactive process viewer</title>
    <link href="http://fanshiqing.github.io/2017/06/18/htop/"/>
    <id>http://fanshiqing.github.io/2017/06/18/htop/</id>
    <published>2017-06-18T06:42:01.000Z</published>
    <updated>2017-07-04T08:00:01.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="htop命令简介"><a href="#htop命令简介" class="headerlink" title="htop命令简介"></a>htop命令简介</h1><p><code>htop</code>是Linux系统下的一个<strong>交互式</strong>、<strong>实时</strong>进程监控应用程序，<code>top</code>的高级版。</p><p>优点：</p><ul><li>可以横向或纵向滚动浏览进程列表，以便查看所有的进程和<strong>完整的命令行</strong></li><li>支持<strong>鼠标操作</strong></li><li>杀进程时不需要输入进程号(快捷键: <code>F9</code>)</li></ul><h2 id="htop-vs-top"><a href="#htop-vs-top" class="headerlink" title="htop vs top"></a>htop vs top</h2><blockquote><p>It is similar to top, but allows you to scroll vertically and horizon-<br>       tally, so you can see all the processes running on the  system,  along<br>       with  their  full  command lines, as well as viewing them as a process<br>       tree, selecting multiple processes and acting on them all at once.<br>Tasks related to processes (killing, renicing)  can  be  done  without<br>       entering their PIDs. (摘自<code>htop</code>手册:)</p></blockquote><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>For Mac OS:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ brew install htop</div></pre></td></tr></table></figure><p>For Ubuntu 14.04 LTS:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ sudo apt-get install htop</div></pre></td></tr></table></figure><p>查看命令手册：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ man htop</div></pre></td></tr></table></figure><p>启动htop：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ htop</div></pre></td></tr></table></figure><p>将得到如下类似的一个实时进程监控窗口：<br><img src="https://ooo.0o0.ooo/2017/07/03/5959f95e6c77f.png" alt="htop panel"></p><p>帮助：按<code>F1</code>进入使用帮助。</p><p>退出：按下<code>q</code>键退出htop面板。</p><h1 id="监控面板介绍"><a href="#监控面板介绍" class="headerlink" title="监控面板介绍"></a>监控面板介绍</h1><h2 id="系统CPU使用率"><a href="#系统CPU使用率" class="headerlink" title="系统CPU使用率"></a>系统CPU使用率</h2><p><img src="https://ooo.0o0.ooo/2017/07/03/595a490e9ef34.png" alt="cpu-usage"></p><p>图中上半部分中的数字<code>1</code>到<code>8</code>表示系统中CPU/Core的数量，而紧邻数字的右侧进度条则相应地表示了对应CPU/Core的实时负载。进度条中不同颜色具有不同的含义<font color="grey">(以下为默认配置，具体操作时可以在<code>F2-&gt;Setup-&gt;Colors</code>列表中选择不同的主题)</font>：</p><ul><li><strong>CPU使用率栏</strong>: [<font color="blue">低优先级进程/</font><font color="green">用户进程/</font><font color="red">内核进程</font> &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; <font color="grey">used%</font>]</li></ul><h2 id="系统内存使用率"><a href="#系统内存使用率" class="headerlink" title="系统内存使用率"></a>系统内存使用率</h2><ul><li><strong>Memory使用率栏</strong>：[<font color="green">已使用/</font><font color="blue">buffers/</font><font color="orange">cache</font> &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; &ensp; <font color="grey">used/total</font>]</li></ul><h2 id="系统平均负载"><a href="#系统平均负载" class="headerlink" title="系统平均负载"></a>系统平均负载</h2><p><img src="https://ooo.0o0.ooo/2017/07/03/595a45a4a111c.png" alt="load average"></p><ul><li><strong>负载</strong>(<a href="https://en.wikipedia.org/wiki/Load_(computing" target="_blank" rel="external">Load</a>)): 运行队列(run-queue)的长度：L = 等待进程的数目 + 运行进程的数目</li><li><strong>平均负载</strong>(<a href="https://www.howtogeek.com/194642/understanding-the-load-average-on-linux-and-other-unix-like-systems/" target="_blank" rel="external">load average</a>) 在<strong>一段时间内</strong>CPU正在处理以及等待CPU处理的进程数之和的统计信息，也就是CPU使用队列的长度的统计信息<blockquote><p><code>“最大负载=核心数”法则</code> 在多核处理中，负载不应该高于<strong>处理器核心的总数量</strong>。<font color="grey"><a href="http://blog.scoutapp.com/articles/2009/07/31/understanding-load-averages" target="_blank" rel="external">source</a></font></p></blockquote></li></ul><p>上图中<code>Load average</code>之后的3个数字显示的是系统在<code>1分钟</code>，<code>5分钟</code>，<code>15分钟</code>之内的平均负载值。(注： <code>uptime</code>命令可以直接查看load average)</p><h2 id="进程详细实时信息列表"><a href="#进程详细实时信息列表" class="headerlink" title="进程详细实时信息列表"></a>进程详细实时信息列表</h2><p><img src="https://ooo.0o0.ooo/2017/07/03/595a48b21eaa3.png" alt="processes-info"></p><p>每一列依次表示：</p><ul><li><strong>PID</strong> 进程ID</li><li><strong>USER</strong> 进程的所有者</li><li><strong>PRI</strong> 进程优先级。数字越小，优先级越高。</li><li><strong>NI</strong> 进程的<code>nice</code>值（负值表示高优先级，正值表示低优先级）</li><li><strong>VIRT</strong> 进程使用的虚拟内存</li><li><strong>RES</strong> 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA</li><li><strong>S</strong> 进程状态<ul><li><font color="green">R</font> (Running) &ensp; &ensp; 可执行状态（<font color="red">运行/就绪</font>)</li><li>D (uninterruptedly sleeping) &ensp; &ensp; <font color="red">不可中断的睡眠状态</font>.通常是在等待IO，比如磁盘IO，网络IO，其他外设IO (该状态不接收外来的任何信号，因此无法用kill杀掉D状态的进程)</li><li>S (sleeping) &ensp; &ensp; <font color="red">可中断的睡眠状态</font>(因为等待某某事件的发生(比如等待socket连接、等待信号量),而被挂起)</li><li>T (traced) &ensp; &ensp; 暂停状态或跟踪状态 (例如在<code>gdb</code>中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于task_traced状态)</li><li>Z (zombied) &ensp; &ensp; 退出状态，进程成为僵尸进程(已经结束了的进程，但是没有从进程表中删除)</li></ul></li><li><font color="red"><strong>CPU%</strong></font> 进程的CPU时间片利用率</li><li><font color="red"><strong>MEM%</strong></font> 进程的物理内存利用率</li><li><strong>TIME+</strong> 进程使用的处理器时间总计</li><li><font color="red"><strong>Command</strong></font> 启动该进程的完整命令行</li></ul><p>最后一行是F1~F10的功能菜单和对应的字母快捷键。</p><h1 id="Read-More"><a href="#Read-More" class="headerlink" title="Read More"></a>Read More</h1><p><a href="https://www.howtogeek.com/194642/understanding-the-load-average-on-linux-and-other-unix-like-systems/" target="_blank" rel="external">Understanding the Load Average on Linux and Other Unix-like Systems</a><br><a href="http://blog.scoutapp.com/articles/2009/07/31/understanding-load-averages" target="_blank" rel="external">Understanding Linux CPU Load - when should you be worried?</a><br><a href="http://www.deonsworld.co.za/2012/12/20/understanding-and-using-htop-monitor-system-resources/" target="_blank" rel="external">Understanding and using htop to monitor system resources</a><br><a href="http://www.brendangregg.com/Slides/Velocity2015_LinuxPerfTools.pdf" target="_blank" rel="external">Linux    Performance Tools</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;htop命令简介&quot;&gt;&lt;a href=&quot;#htop命令简介&quot; class=&quot;headerlink&quot; title=&quot;htop命令简介&quot;&gt;&lt;/a&gt;htop命令简介&lt;/h1&gt;&lt;p&gt;&lt;code&gt;htop&lt;/code&gt;是Linux系统下的一个&lt;strong&gt;交互式&lt;/stro
      
    
    </summary>
    
      <category term="Linux性能分析工具" scheme="http://fanshiqing.github.io/categories/Linux%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7/"/>
    
    
      <category term="Linux" scheme="http://fanshiqing.github.io/tags/Linux/"/>
    
      <category term="Linux性能分析" scheme="http://fanshiqing.github.io/tags/Linux%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    
  </entry>
  
  <entry>
    <title>算法基础</title>
    <link href="http://fanshiqing.github.io/2017/06/15/%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"/>
    <id>http://fanshiqing.github.io/2017/06/15/算法基础/</id>
    <published>2017-06-15T13:59:17.000Z</published>
    <updated>2017-08-17T01:29:29.000Z</updated>
    
    <content type="html"><![CDATA[<script src=/js/crypto-js.js></script><script>function doDecrypt(pwd, onError) {console.log("in doDecrypt");var txt = document.getElementById("enc_content").innerHTML;var plantext;try {  var bytes = CryptoJS.AES.decrypt(txt, pwd);plaintext = bytes.toString(CryptoJS.enc.Utf8);} catch(err) {if(onError) {onError(err);}return;}document.getElementById("enc_content").innerHTML = plaintext;document.getElementById("enc_content").style.display = "block";   document.getElementById("enc_passwd").style.display = "none";}</script><div id="enc_content" style="display:none">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</div><div id="enc_passwd"> <input id="enc_pwd_input" type="text" style="border-radius: 5px;border-style: groove;height: 30px;width: 50%;cursor: auto;font-size: 102%;color: currentColor;outline: none;text-overflow: initial;padding-left: 5px;" onkeydown="if (event.keyCode == 13) { decrypt(); return false;}"> <input type="submit" value="解&nbsp;密" onclick="decrypt()" style="width: 58px;height: 34px;border-radius: 5px;background-color: white;border-style: solid;color: currentColor;"><div id="enc_error" style="display: inline-block;color: #d84527;margin-left: 10px"></div><script>var onError = function(error) {document.getElementById("enc_error").innerHTML = "password error!"};function decrypt() {var passwd = document.getElementById("enc_pwd_input").value;console.log(passwd);doDecrypt(passwd, onError);}</script></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;script src=/js/crypto-js.js&gt;&lt;/script&gt;&lt;script&gt;
function doDecrypt(pwd, onError) {
	console.log(&quot;in doDecrypt&quot;);
	var txt = document.getEleme
      
    
    </summary>
    
    
      <category term="算法" scheme="http://fanshiqing.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>【闲情】记 第二届南大上海校友会新年羽毛球嘉年华</title>
    <link href="http://fanshiqing.github.io/2017/01/07/%E9%97%B2%E6%83%85-%E8%AE%B0%E7%AC%AC%E4%BA%8C%E5%B1%8A%E5%8D%97%E5%A4%A7%E4%B8%8A%E6%B5%B7%E6%A0%A1%E5%8F%8B%E4%BC%9A%E6%96%B0%E5%B9%B4%E7%BE%BD%E6%AF%9B%E7%90%83%E5%98%89%E5%B9%B4%E5%8D%8E/"/>
    <id>http://fanshiqing.github.io/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/</id>
    <published>2017-01-07T14:00:00.000Z</published>
    <updated>2017-07-09T10:57:25.000Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h4><ul><li>时间： 2017年1月7日</li><li>地点：上海财大（武川路校区）羽毛球馆（旧馆）</li><li>事件：第二届南大上海校友会新年羽毛球嘉年华活动</li><li>角色：第二次参加这个活动，本次担任 <font color="red">杨浦队</font> <strong>队长</strong> ^_^</li><li>赛制：趣味赛 + 团体赛</li><li><p>赛果：杨浦队在8支参赛队中勇夺 <strong><em>第4名</em></strong> (历史最好成绩)！</p><blockquote><ul><li>趣味赛:<ol><li>单手颠球，穿越障碍</li><li>三人隔网，你发我接（限时）</li></ol></li><li>团体赛(8支)<ul><li>徐汇、闵松、沿江、张江、花木、<font color="red"><strong>杨浦</strong></font>、长静黄联队、市北联队</li></ul></li></ul></blockquote></li><li><p>赛后聚餐地点：上海财大豪生酒店</p></li></ul><h4 id="赛前宣传海报-感谢-陈雨致-学姐的精心设计-："><a href="#赛前宣传海报-感谢-陈雨致-学姐的精心设计-：" class="headerlink" title="赛前宣传海报(感谢@陈雨致 学姐的精心设计)："></a>赛前宣传海报(感谢@陈雨致 学姐的精心设计)：</h4><p><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/比赛海报.jpeg" alt="比赛海报"><br><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/各队队长.jpeg" alt=""></p><h4 id="赛前集体合影-每队一列，列首为该队队长"><a href="#赛前集体合影-每队一列，列首为该队队长" class="headerlink" title="赛前集体合影(每队一列，列首为该队队长):"></a>赛前集体合影(每队一列，列首为该队队长):</h4><p><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/赛前全体合影.JPG" alt=""><br><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/大合影.jpeg" alt=""></p><h4 id="高质量的比赛场馆-感谢-王绍立学长大力帮助联系和提供场地！"><a href="#高质量的比赛场馆-感谢-王绍立学长大力帮助联系和提供场地！" class="headerlink" title="高质量的比赛场馆(感谢@王绍立学长大力帮助联系和提供场地！):"></a>高质量的比赛场馆(感谢@王绍立学长大力帮助联系和提供场地！):</h4><p><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/比赛场地.jpeg" alt=""></p><h4 id="比赛中："><a href="#比赛中：" class="headerlink" title="比赛中："></a>比赛中：</h4><p><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/比赛中.jpeg" alt=""><br><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/小宇宙组合.jpeg" alt=""></p><h4 id="赛果"><a href="#赛果" class="headerlink" title="赛果:"></a>赛果:</h4><ul><li>冠军：闵松队(根据约定，本次比赛冠军将负责主办明年的第三届比赛^_-)</li><li>亚军：沿江队</li><li>季军：张江队</li><li>殿军：<font color="red">杨浦队</font></li></ul><p><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/赛果.jpeg" alt=""></p><h4 id="赛后各队队长、裁判、志愿者们合影"><a href="#赛后各队队长、裁判、志愿者们合影" class="headerlink" title="赛后各队队长、裁判、志愿者们合影:"></a>赛后各队队长、裁判、志愿者们合影:</h4><p><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/志愿者.jpeg" alt=""></p><h4 id="大杨浦队赛后合影留念"><a href="#大杨浦队赛后合影留念" class="headerlink" title="大杨浦队赛后合影留念"></a>大杨浦队赛后合影留念</h4><p><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/yangpu1.jpeg" alt=""><br><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/yangpu2.jpeg" alt=""></p><h4 id="赛后聚餐"><a href="#赛后聚餐" class="headerlink" title="赛后聚餐:"></a>赛后聚餐:</h4><p><img src="/2017/01/07/闲情-记第二届南大上海校友会新年羽毛球嘉年华/赛后聚餐.jpeg" alt=""></p><h4 id="广告时间"><a href="#广告时间" class="headerlink" title="广告时间"></a>广告时间</h4><p>感谢<font color="red">炜觉资本</font>对本次活动的大力赞助！</p><hr><p>明年再来，<font color="red">闵松</font>主办！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;Abstract&quot;&gt;&lt;a href=&quot;#Abstract&quot; class=&quot;headerlink&quot; title=&quot;Abstract&quot;&gt;&lt;/a&gt;Abstract&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;时间： 2017年1月7日&lt;/li&gt;
&lt;li&gt;地点：上海财大（武川路校区）羽毛球
      
    
    </summary>
    
      <category term="闲情" scheme="http://fanshiqing.github.io/categories/%E9%97%B2%E6%83%85/"/>
    
    
      <category term="闲情" scheme="http://fanshiqing.github.io/tags/%E9%97%B2%E6%83%85/"/>
    
      <category term="羽毛球" scheme="http://fanshiqing.github.io/tags/%E7%BE%BD%E6%AF%9B%E7%90%83/"/>
    
      <category term="相册" scheme="http://fanshiqing.github.io/tags/%E7%9B%B8%E5%86%8C/"/>
    
  </entry>
  
  <entry>
    <title>CaffeNet vs CaffeOnSpark</title>
    <link href="http://fanshiqing.github.io/2016/05/12/CaffeNet-vs-CaffeOnSpark/"/>
    <id>http://fanshiqing.github.io/2016/05/12/CaffeNet-vs-CaffeOnSpark/</id>
    <published>2016-05-12T05:28:20.000Z</published>
    <updated>2017-07-04T06:16:14.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="SparkNet"><a href="#SparkNet" class="headerlink" title="SparkNet"></a>SparkNet</h1><p><a href="https://github.com/amplab/SparkNet" target="_blank" rel="external">SparkNet</a> 是由amplab开发的基于Spark的分布式深度神经网络架构，2015年11月份在github上开源. 该系统开发的动机在于当下流行的批处理计算框架（MapReduce、Spark等）都不是设计用来支持已有的分布式深度学习系统下的异步的、通行密集型的任务。SparkNet将已有的数据处理框架（Spark)和流行的、高效的深度学习框架Caffe整合到一起，同时提供了Spark RDDs和Caffe的访问接口；并通过改进的并行化SGD算法来降低节点间的通信开销[1].</p><p>SparkNet的架构示例如<code>图1</code>所示[1]。</p><p><img src="http://ww3.sinaimg.cn/large/006HJ39wgy1fh7t47ans2j30f4068wfl.jpg" alt="SparkNet-Archi"></p><p><code>图1</code>是由5个节点组成的EC2集群。其中Master节点负责向其余4各worker节点分发任务；每个worker在本地单独使用基于GPU的caffe来进行训练；本地训练结束后各个worker将参数回传给Master;Master收集各个worker的参数后做全局的处理（例如average）再broadcast给各个worker以进行下一轮的迭代。</p><h1 id="CaffeOnSpark"><a href="#CaffeOnSpark" class="headerlink" title="CaffeOnSpark"></a>CaffeOnSpark</h1><p><a href="https://github.com/yahoo/CaffeOnSpark" target="_blank" rel="external">CaffeOnSpark</a> 由Yahoo开发，并于今年2月份开源在github上。该系统旨在将深度学习步骤(训练、测试等)无缝地嵌入到Spark应用中，使得直接在存储数据的(强化的)Hadoop集群上进行深度学习成为可能，从而避免了数据在Hadoop集群和深度学习集群之间不必要的传输. 作为Spark的深度学习包，CaffeOnSpark填补了<code>Spark MLlib</code>在DL能力上的不足[3]。可以这样说，CaffeOnSpark集合了Caffe和Spark两者之长，并应用到大规模深度学习上，使得我们能像操作其他Spark应用一样操作深度学习任务。</p><p>CaffeOnSpark的系统架构图如<code>图2</code>[6] 所示：</p><p><img src="http://ww1.sinaimg.cn/large/006HJ39wgy1fh7t5uf29fj30ff0bb76e.jpg" alt=""><br>&ensp;&ensp; &ensp; &ensp; &ensp; &ensp; &ensp;&ensp; &ensp; &ensp; &ensp; &ensp; &ensp;<strong>图2. CaffeOnSpark System Architecture</strong></p><p>从图2中我们看到CaffeOnSpark在<strong>参数的同步/管理</strong>操作上和SparkNet是完全不同的：CaffeOnSpark executors之间通过<code>MPI_ALLREDUCE</code>接口通信（通过底层<code>RDMA/Infiniband</code> 或者TCP/Ethenet来保证GPU间高速的数据传输,10x于CPU).在这种通信模式下，各个节点/Caffe引擎之间是<strong>peer-to-peer</strong>的模式；而<code>SparkNet</code>的设计中依然保留了Spark的<strong>主/从模式</strong>。</p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>CaffeOnSpark和SparkNet的相同之处在于两者都使得Spark集群下基于Caffe的深度学习成为可能。</p><p>而两者最显著的不同在于两者在系统框架设计中对于参数同步所采用的不同方案。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p>[1]. Moritz,Philipp, et al. “SparkNet: Training Deep Networks in Spark.” arXiv preprint arXiv:1511.06051 (2015).<br>[2]. <a href="https://www.slideshare.net/HadoopSummit/distributed-deep-learning-on-hadoop-clusters" target="_blank" rel="external">Large Scale Distributed Deep Learning on Hadoop Clusters, PPT</a><br>[3]. GitHub - amplab/SparkNet, <a href="https://github.com/amplab/SparkNet" target="_blank" rel="external">https://github.com/amplab/SparkNet</a><br>[4]. GitHub - yahoo/CaffeOnSpark, <a href="https://github.com/yahoo/CaffeOnSpark" target="_blank" rel="external">https://github.com/yahoo/CaffeOnSpark</a><br>[5]. CaffeOnSpark Google Group, <a href="https://groups.google.com/forum/#!forum/sparknet-users" target="_blank" rel="external">https://groups.google.com/forum/#!forum/sparknet-users</a><br>[6]. <a href="http://www.deepminder.com/?p=2647" target="_blank" rel="external">Large Scale Distributed Deep Learning on Hadoop Clusters</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;SparkNet&quot;&gt;&lt;a href=&quot;#SparkNet&quot; class=&quot;headerlink&quot; title=&quot;SparkNet&quot;&gt;&lt;/a&gt;SparkNet&lt;/h1&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/amplab/SparkNet&quot; t
      
    
    </summary>
    
      <category term="深度学习" scheme="http://fanshiqing.github.io/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="深度学习框架" scheme="http://fanshiqing.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/"/>
    
  </entry>
  
</feed>
